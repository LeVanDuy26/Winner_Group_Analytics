{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d722cd8",
   "metadata": {},
   "source": [
    "# Notebook: Transform d·ªØ li·ªáu t·ª´ t·∫ßng Bronze l√™n t·∫ßng Silver\n",
    "\n",
    "## M·ª•c ti√™u\n",
    "Transform d·ªØ li·ªáu customer t·ª´ t·∫ßng Bronze (raw JSON) l√™n t·∫ßng Silver (structured data) v·ªõi c√°c b∆∞·ªõc:\n",
    "1. **Extract**: Parse JSON th√†nh tabular format\n",
    "2. **Transform**: L√†m s·∫°ch v√† chu·∫©n h√≥a d·ªØ li·ªáu  \n",
    "3. **Load**: L∆∞u v√†o Silver layer v·ªõi schema t·ªëi ∆∞u\n",
    "4. **Document**: T·∫°o Data Dictionary\n",
    "\n",
    "## Quy tr√¨nh 8 b∆∞·ªõc chu·∫©n\n",
    "1. **Import & Connect DB** - Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng\n",
    "2. **Load d·ªØ li·ªáu t·ª´ Bronze** - ƒê·ªçc raw data\n",
    "3. **JSON Structure Analysis** - Ph√¢n t√≠ch c·∫•u tr√∫c JSON\n",
    "4. **Parse & Flatten JSON** - Chuy·ªÉn ƒë·ªïi sang tabular\n",
    "5. **Data Quality Check** - ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu\n",
    "6. **Data Cleaning** - L√†m s·∫°ch v√† chu·∫©n h√≥a\n",
    "7. **Load v√†o Silver** - L∆∞u v·ªõi schema t·ªëi ∆∞u\n",
    "8. **Data Dictionary** - T·∫°o t√†i li·ªáu metadata\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fb817f",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 1: Import & Connect DB\n",
    "\n",
    "### M·ª•c ti√™u\n",
    "- Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "- Load bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file `.env`\n",
    "- T·∫°o k·∫øt n·ªëi t·ªõi MySQL database\n",
    "\n",
    "### K·∫øt n·ªëi Database\n",
    "- `bronze_engine` ‚Üí ƒê·ªçc d·ªØ li·ªáu g·ªëc t·ª´ schema **Bronze**\n",
    "- `silver_engine` ‚Üí Ghi d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch sang schema **Silver**\n",
    "\n",
    "> **L∆∞u √Ω**: ƒê√¢y l√† b∆∞·ªõc kh·ªüi t·∫°o, ch∆∞a c√≥ quy·∫øt ƒë·ªãnh g√¨, ch·ªâ thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng l√†m vi·ªác.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e442513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ k·∫øt n·ªëi Bronze v√† Silver database th√†nh c√¥ng\n",
      "üìä Bronze DB: winner_bronze\n",
      "üìä Silver DB: winner_silver\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "# Load bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env\n",
    "load_dotenv()\n",
    "\n",
    "# L·∫•y th√¥ng tin k·∫øt n·ªëi database\n",
    "DB_USER   = os.getenv(\"DB_USER\")\n",
    "DB_PASS   = os.getenv(\"DB_PASS\")\n",
    "DB_HOST   = os.getenv(\"DB_HOST\")\n",
    "DB_PORT   = os.getenv(\"DB_PORT\")\n",
    "DB_BRONZE = os.getenv(\"DB_BRONZE\")\n",
    "DB_SILVER = os.getenv(\"DB_SILVER\")\n",
    "\n",
    "# T·∫°o k·∫øt n·ªëi t·ªõi Bronze v√† Silver database\n",
    "bronze_engine = create_engine(f\"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_BRONZE}\")\n",
    "silver_engine = create_engine(f\"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_SILVER}\")\n",
    "\n",
    "print(\"‚úÖ ƒê√£ k·∫øt n·ªëi Bronze v√† Silver database th√†nh c√¥ng\")\n",
    "print(f\"üìä Bronze DB: {DB_BRONZE}\")\n",
    "print(f\"üìä Silver DB: {DB_SILVER}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab7ae6",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 2: Load d·ªØ li·ªáu t·ª´ Bronze\n",
    "\n",
    "### M·ª•c ti√™u\n",
    "- L·∫•y to√†n b·ªô b·∫£ng `customers_raw` t·ª´ Bronze database\n",
    "- Hi·ªÉn th·ªã th√¥ng tin c∆° b·∫£n v·ªÅ dataset (shape, columns)\n",
    "- Xem 1 record JSON m·∫´u ƒë·ªÉ n·∫Øm c·∫•u tr√∫c d·ªØ li·ªáu\n",
    "\n",
    "### Quy tr√¨nh\n",
    "1. **Load data**: ƒê·ªçc t·ª´ `customers_raw` table\n",
    "2. **Basic info**: Hi·ªÉn th·ªã shape v√† columns\n",
    "3. **Sample JSON**: Parse v√† hi·ªÉn th·ªã 1 record m·∫´u\n",
    "\n",
    "> **Decision Point**: T·ª´ JSON m·∫´u, ta s·∫Ω quan s√°t ƒë·ªÉ x√°c ƒë·ªãnh c√≥ nh·ªØng nh√≥m tr∆∞·ªùng n√†o (ƒë·ªãnh danh, h√†nh vi, ƒë·ªãa ch·ªâ...) v√† quy·∫øt ƒë·ªãnh s·∫Ω extract nh·ªØng field n√†o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b0e79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TH√îNG TIN DATASET ===\n",
      "üìä Shape: (36090, 4)\n",
      "üìã Columns: ['shop_id', 'customer_id', 'raw_json', 'extracted_at']\n",
      "üíæ Memory usage: 107.94 MB\n",
      "\n",
      "=== JSON STRUCTURE SAMPLE ===\n",
      "{\n",
      "  \"returned_order_count\": 0,\n",
      "  \"is_block\": false,\n",
      "  \"customer_id\": \"c7a583d6-392d-4308-a02b-67c001ee03db\",\n",
      "  \"count_referrals\": 0,\n",
      "  \"username\": null,\n",
      "  \"emails\": [],\n",
      "  \"inserted_at\": \"2025-08-16T02:19:59\",\n",
      "  \"creator\": null,\n",
      "  \"list_voucher\": [],\n",
      "  \"name\": \"Thinh Bui\",\n",
      "  \"assigned_user_id\": null,\n",
      "  \"last_order_at\": null,\n",
      "  \"date_of_birth\": null,\n",
      "  \"id\": \"e906c5c7-ea19-42e5-a971-57cf09c94417\",\n",
      "  \"fb_id\": \"377626778776391_31407011708897267\",\n",
      "  \"notes\": [],\n",
      "  \"total_amount_referred\": null,\n",
      "  \"is_adjust_debts\": null,\n",
      "  \"is_discount_by_level\": true,\n",
      "  \"updated_at\": \"2025-08-16T02:19:59\",\n",
      "  \"conversation_link\": \"https://pancake.vn/377626778776391?customer_id=c7a583d6-392d-4308-a02b-67c001ee03db\",\n",
      "  \"order_count\": 1,\n",
      "  \"order_sources\": [\n",
      "    \"-1\"\n",
      "  ],\n",
      "  \"tags\": [],\n",
      "  \"succeed_order_count\": 0,\n",
      "  \"user_block_id\": null,\n",
      "  \"phone_numbers\": [\n",
      "    \"0903693389\"\n",
      "  ],\n",
      "  \"reward_point\": 0,\n",
      "  \"shop_id\": 230361475,\n",
      "  \"current_debts\": 0,\n",
      "  \"level\": null,\n",
      "  \"purchased_amount\": 0,\n",
      "  \"creator_id\": null,\n",
      "  \"gender\": \"male\",\n",
      "  \"shop_customer_addresses\": [],\n",
      "  \"conversation_tags\": null,\n",
      "  \"referral_code\": \"GM5wdxsy\",\n",
      "  \"active_levera_pay\": false,\n",
      "  \"currency\": null,\n",
      "  \"used_reward_point\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load d·ªØ li·ªáu customers t·ª´ Bronze database\n",
    "customers_df = pd.read_sql(\"SELECT * FROM customers_raw\", bronze_engine)\n",
    "\n",
    "# Hi·ªÉn th·ªã th√¥ng tin c∆° b·∫£n v·ªÅ dataset\n",
    "print(\"=== TH√îNG TIN DATASET ===\")\n",
    "print(f\"üìä Shape: {customers_df.shape}\")\n",
    "print(f\"üìã Columns: {list(customers_df.columns)}\")\n",
    "print(f\"üíæ Memory usage: {customers_df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Hi·ªÉn th·ªã 1 record JSON m·∫´u ƒë·ªÉ n·∫Øm c·∫•u tr√∫c\n",
    "print(\"\\n=== JSON STRUCTURE SAMPLE ===\")\n",
    "sample_json = json.loads(customers_df[\"raw_json\"].iloc[0])\n",
    "print(json.dumps(sample_json, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578e6a0",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 3: JSON Structure Analysis\n",
    "\n",
    "### M·ª•c ti√™u\n",
    "- Scan to√†n b·ªô keys trong JSON ƒë·ªÉ hi·ªÉu ƒë·∫ßy ƒë·ªß c·∫•u tr√∫c\n",
    "- Ph√¢n lo·∫°i c√°c tr∆∞·ªùng theo m·ª©c ƒë·ªô quan tr·ªçng\n",
    "- Chu·∫©n b·ªã cho vi·ªác l·ª±a ch·ªçn fields ƒë·ªÉ extract\n",
    "\n",
    "### Quy tr√¨nh\n",
    "1. **Scan keys**: Duy·ªát qua 200 records ƒë·∫ßu ƒë·ªÉ l·∫•y t·∫•t c·∫£ keys\n",
    "2. **Categorize**: Ph√¢n lo·∫°i keys theo business value\n",
    "3. **Decision**: Quy·∫øt ƒë·ªãnh extract nh·ªØng field n√†o\n",
    "\n",
    "> **Decision Point**: T·ª´ danh s√°ch keys, ta s·∫Ω quy·∫øt ƒë·ªãnh ch·ªçn nh·ªØng c·ªôt quan tr·ªçng ƒë·ªÉ parse (v√≠ d·ª•: customer_id, name, gender, order_count...) v√† b·ªè c√°c c·ªôt √≠t gi√° tr·ªã (notes, creator...).\n",
    "\n",
    "### Ph√¢n lo·∫°i tr∆∞·ªùng theo m·ª©c ƒë·ªô quan tr·ªçng:\n",
    "- **High Priority**: ƒê·ªãnh danh, th√¥ng tin c∆° b·∫£n, metrics ch√≠nh\n",
    "- **Medium Priority**: Th√¥ng tin b·ªï sung, h√†nh vi\n",
    "- **Low Priority**: Metadata, logs, fields √≠t s·ª≠ d·ª•ng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0e1ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SCANNING JSON KEYS ===\n",
      "üìä T·ªïng s·ªë keys t√¨m th·∫•y: 40\n",
      "üìã Danh s√°ch keys (sorted):\n",
      " 1. active_levera_pay\n",
      " 2. assigned_user_id\n",
      " 3. conversation_link\n",
      " 4. conversation_tags\n",
      " 5. count_referrals\n",
      " 6. creator\n",
      " 7. creator_id\n",
      " 8. currency\n",
      " 9. current_debts\n",
      "10. customer_id\n",
      "11. date_of_birth\n",
      "12. emails\n",
      "13. fb_id\n",
      "14. gender\n",
      "15. id\n",
      "16. inserted_at\n",
      "17. is_adjust_debts\n",
      "18. is_block\n",
      "19. is_discount_by_level\n",
      "20. last_order_at\n",
      "21. level\n",
      "22. list_voucher\n",
      "23. name\n",
      "24. notes\n",
      "25. order_count\n",
      "26. order_sources\n",
      "27. phone_numbers\n",
      "28. purchased_amount\n",
      "29. referral_code\n",
      "30. returned_order_count\n",
      "31. reward_point\n",
      "32. shop_customer_addresses\n",
      "33. shop_id\n",
      "34. succeed_order_count\n",
      "35. tags\n",
      "36. total_amount_referred\n",
      "37. updated_at\n",
      "38. used_reward_point\n",
      "39. user_block_id\n",
      "40. username\n",
      "\n",
      "=== NESTED STRUCTURE ANALYSIS ===\n",
      "üìä C·∫•u tr√∫c nested objects v√† arrays:\n"
     ]
    }
   ],
   "source": [
    "# Scan t·∫•t c·∫£ keys trong JSON ƒë·ªÉ hi·ªÉu ƒë·∫ßy ƒë·ªß c·∫•u tr√∫c\n",
    "print(\"=== SCANNING JSON KEYS ===\")\n",
    "all_keys = set()\n",
    "\n",
    "# Scan 200 records ƒë·∫ßu ti√™n ƒë·ªÉ l·∫•y t·∫•t c·∫£ keys c√≥ th·ªÉ c√≥\n",
    "for raw in customers_df[\"raw_json\"].head(200):\n",
    "    d = json.loads(raw)\n",
    "    all_keys.update(d.keys())\n",
    "\n",
    "print(f\"üìä T·ªïng s·ªë keys t√¨m th·∫•y: {len(all_keys)}\")\n",
    "print(f\"üìã Danh s√°ch keys (sorted):\")\n",
    "for i, key in enumerate(sorted(all_keys), 1):\n",
    "    print(f\"{i:2d}. {key}\")\n",
    "\n",
    "# Ph√¢n t√≠ch c·∫•u tr√∫c nested\n",
    "print(f\"\\n=== NESTED STRUCTURE ANALYSIS ===\")\n",
    "sample_data = json.loads(customers_df[\"raw_json\"].iloc[0])\n",
    "\n",
    "def analyze_nested_structure(data, prefix=\"\"):\n",
    "    \"\"\"Ph√¢n t√≠ch c·∫•u tr√∫c nested objects v√† arrays\"\"\"\n",
    "    structure = {}\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, dict):\n",
    "            structure[f\"{prefix}{key}\"] = \"object\"\n",
    "            structure.update(analyze_nested_structure(value, f\"{prefix}{key}.\"))\n",
    "        elif isinstance(value, list) and value:\n",
    "            structure[f\"{prefix}{key}\"] = f\"array[{len(value)}]\"\n",
    "            if value and isinstance(value[0], dict):\n",
    "                structure.update(analyze_nested_structure(value[0], f\"{prefix}{key}[0].\"))\n",
    "        else:\n",
    "            structure[f\"{prefix}{key}\"] = type(value).__name__\n",
    "    return structure\n",
    "\n",
    "nested_structure = analyze_nested_structure(sample_data)\n",
    "print(f\"üìä C·∫•u tr√∫c nested objects v√† arrays:\")\n",
    "for key, value_type in sorted(nested_structure.items()):\n",
    "    if \".\" in key or \"[\" in key:  # Ch·ªâ hi·ªÉn th·ªã nested structures\n",
    "        print(f\"  {key}: {value_type}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1a915",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 4: Parse & Flatten JSON\n",
    "\n",
    "### M·ª•c ti√™u\n",
    "- ƒê·ªãnh nghƒ©a h√†m parse_customer ƒë·ªÉ extract c√°c tr∆∞·ªùng ƒë√£ ch·ªçn\n",
    "- Flatten c√°c tr∆∞·ªùng nested nh∆∞ phone_numbers, emails, order_sources\n",
    "- Parse nested objects nh∆∞ shop_customer_addresses\n",
    "- Chuy·ªÉn ƒë·ªïi t·ª´ JSON sang DataFrame tabular\n",
    "\n",
    "### Quy tr√¨nh\n",
    "1. **Define parsing function**: T·∫°o h√†m parse_customer v·ªõi logic extract\n",
    "2. **Handle arrays**: Chuy·ªÉn arrays th√†nh comma-separated strings\n",
    "3. **Handle nested objects**: Extract fields t·ª´ nested objects\n",
    "4. **Apply parsing**: √Åp d·ª•ng h√†m cho to√†n b·ªô dataset\n",
    "\n",
    "### C√°c tr∆∞·ªùng ƒë∆∞·ª£c ch·ªçn (25 fields)\n",
    "**ƒê·ªãnh danh & C∆° b·∫£n**: customer_id, id, name, shop_id\n",
    "**Th√¥ng tin c√° nh√¢n**: gender, phone_numbers, emails, date_of_birth  \n",
    "**H√†nh vi mua h√†ng**: order_count, succeed_order_count, returned_order_count, purchased_amount, last_order_at\n",
    "**Th·ªùi gian**: inserted_at, updated_at\n",
    "**Tr·∫°ng th√°i**: is_block, is_discount_by_level, active_levera_pay\n",
    "**T√†i ch√≠nh & Loyalty**: reward_point, used_reward_point, current_debts, count_referrals, total_amount_referred\n",
    "**Marketing & Tracking**: referral_code, fb_id, order_sources, conversation_link\n",
    "**ƒê·ªãa ch·ªâ**: shop_customer_addresses (nested)\n",
    "**Metadata**: currency\n",
    "\n",
    "> **Decision Point**: Sau cell n√†y, ta c√≥ b·∫£ng d·∫°ng s·∫°ch h∆°n ƒë·ªÉ ki·ªÉm tra ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f0eb402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PARSING JSON DATA ===\n",
      "‚úÖ Parsing completed successfully\n",
      "üìä Parsed shape: (36090, 33)\n",
      "üìã Columns extracted: 33\n",
      "üíæ Memory usage: 48.24 MB\n",
      "\n",
      "=== SAMPLE PARSED DATA ===\n",
      "                            customer_id                                    id  \\\n",
      "0  c7a583d6-392d-4308-a02b-67c001ee03db  e906c5c7-ea19-42e5-a971-57cf09c94417   \n",
      "1  590ba7de-e4fe-43b3-8013-27fc69937edf  6c5b40d2-ae42-4e13-8019-f3f9127d75a0   \n",
      "2  a9e62388-57c2-4834-a87c-7c1025aea92d  765c531b-743f-4f30-b6b0-0d6f3579630f   \n",
      "\n",
      "          name    shop_id gender       phone email date_of_birth  order_count  \\\n",
      "0    Thinh Bui  230361475   male  0903693389  None          None            1   \n",
      "1  Truong Minh  230361475   male  0907809070  None          None            1   \n",
      "2  Quach Quach  230361475   male  0986533988  None          None            1   \n",
      "\n",
      "   succeed_order_count  ...  referral_code                              fb_id  \\\n",
      "0                    0  ...       GM5wdxsy  377626778776391_31407011708897267   \n",
      "1                    0  ...       6zqy77Bu  377626778776391_24536870619280831   \n",
      "2                    0  ...       uyMB3h6E  377626778776391_24712861355019072   \n",
      "\n",
      "  order_sources                                  conversation_link  \\\n",
      "0            -1  https://pancake.vn/377626778776391?customer_id...   \n",
      "1            -1  https://pancake.vn/377626778776391?customer_id...   \n",
      "2            -1  https://pancake.vn/377626778776391?customer_id...   \n",
      "\n",
      "  address_province_id  address_district_id  address_commune_id  address_full  \\\n",
      "0                None                 None                None          None   \n",
      "1                None                 None                None          None   \n",
      "2                None                 None                None          None   \n",
      "\n",
      "   address_postcode currency  \n",
      "0              None     None  \n",
      "1              None     None  \n",
      "2              None     None  \n",
      "\n",
      "[3 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "def parse_customer(row):\n",
    "    \"\"\"\n",
    "    Parse JSON customer data th√†nh tabular format\n",
    "    Extract 25 tr∆∞·ªùng ƒë√£ ch·ªçn v·ªõi x·ª≠ l√Ω arrays v√† nested objects\n",
    "    \"\"\"\n",
    "    d = json.loads(row[\"raw_json\"])\n",
    "    \n",
    "    # X·ª≠ l√Ω nested address object\n",
    "    addr = d.get(\"shop_customer_addresses\", [{}])[0] if d.get(\"shop_customer_addresses\") else {}\n",
    "    \n",
    "    return {\n",
    "        # ƒê·ªãnh danh & C∆° b·∫£n (4 fields)\n",
    "        \"customer_id\": d.get(\"customer_id\"),\n",
    "        \"id\": d.get(\"id\"), \n",
    "        \"name\": d.get(\"name\"),\n",
    "        \"shop_id\": d.get(\"shop_id\"),\n",
    "        \n",
    "        # Th√¥ng tin c√° nh√¢n (4 fields)\n",
    "        \"gender\": d.get(\"gender\"),\n",
    "        \"phone\": \",\".join(d.get(\"phone_numbers\", [])) if d.get(\"phone_numbers\") else None,\n",
    "        \"email\": \",\".join(d.get(\"emails\", [])) if d.get(\"emails\") else None,\n",
    "        \"date_of_birth\": d.get(\"date_of_birth\"),\n",
    "        \n",
    "        # H√†nh vi mua h√†ng (5 fields)\n",
    "        \"order_count\": d.get(\"order_count\"),\n",
    "        \"succeed_order_count\": d.get(\"succeed_order_count\"),\n",
    "        \"returned_order_count\": d.get(\"returned_order_count\"),\n",
    "        \"purchased_amount\": d.get(\"purchased_amount\"),\n",
    "        \"last_order_at\": d.get(\"last_order_at\"),\n",
    "        \n",
    "        # Th·ªùi gian (2 fields)\n",
    "        \"inserted_at\": d.get(\"inserted_at\"),\n",
    "        \"updated_at\": d.get(\"updated_at\"),\n",
    "        \n",
    "        # Tr·∫°ng th√°i (3 fields)\n",
    "        \"is_block\": d.get(\"is_block\"),\n",
    "        \"is_discount_by_level\": d.get(\"is_discount_by_level\"),\n",
    "        \"active_levera_pay\": d.get(\"active_levera_pay\"),\n",
    "        \n",
    "        # T√†i ch√≠nh & Loyalty (5 fields)\n",
    "        \"reward_point\": d.get(\"reward_point\"),\n",
    "        \"used_reward_point\": d.get(\"used_reward_point\"),\n",
    "        \"current_debts\": d.get(\"current_debts\"),\n",
    "        \"count_referrals\": d.get(\"count_referrals\"),\n",
    "        \"total_amount_referred\": d.get(\"total_amount_referred\"),\n",
    "        \n",
    "        # Marketing & Tracking (4 fields)\n",
    "        \"referral_code\": d.get(\"referral_code\"),\n",
    "        \"fb_id\": d.get(\"fb_id\"),\n",
    "        \"order_sources\": \",\".join(d.get(\"order_sources\", [])) if d.get(\"order_sources\") else None,\n",
    "        \"conversation_link\": d.get(\"conversation_link\"),\n",
    "        \n",
    "        # ƒê·ªãa ch·ªâ (nested object - extract key fields)\n",
    "        \"address_province_id\": addr.get(\"province_id\"),\n",
    "        \"address_district_id\": addr.get(\"district_id\"),\n",
    "        \"address_commune_id\": addr.get(\"commune_id\"),\n",
    "        \"address_full\": addr.get(\"full_address\"),\n",
    "        \"address_postcode\": addr.get(\"postcode\"),\n",
    "        \n",
    "        # Metadata (1 field)\n",
    "        \"currency\": d.get(\"currency\")\n",
    "    }\n",
    "\n",
    "# √Åp d·ª•ng parsing function cho to√†n b·ªô dataset\n",
    "print(\"=== PARSING JSON DATA ===\")\n",
    "customers_parsed = customers_df.apply(parse_customer, axis=1, result_type=\"expand\")\n",
    "\n",
    "# Hi·ªÉn th·ªã k·∫øt qu·∫£ parsing\n",
    "print(f\"‚úÖ Parsing completed successfully\")\n",
    "print(f\"üìä Parsed shape: {customers_parsed.shape}\")\n",
    "print(f\"üìã Columns extracted: {len(customers_parsed.columns)}\")\n",
    "print(f\"üíæ Memory usage: {customers_parsed.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Hi·ªÉn th·ªã sample data\n",
    "print(f\"\\n=== SAMPLE PARSED DATA ===\")\n",
    "print(customers_parsed.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b6f3f",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 5: Data Quality Check\n",
    "\n",
    "### M·ª•c ti√™u\n",
    "- T√≠nh t·ª∑ l·ªá null t·ª´ng c·ªôt ƒë·ªÉ quy·∫øt ƒë·ªãnh gi·ªØ/l∆∞·ª£c b·ªè\n",
    "- Check duplicate theo customer_id\n",
    "- In sample values cho c√°c field quan tr·ªçng\n",
    "- ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu t·ªïng th·ªÉ\n",
    "\n",
    "### Quy tr√¨nh\n",
    "1. **Null analysis**: T√≠nh t·ª∑ l·ªá null t·ª´ng c·ªôt\n",
    "2. **Duplicate check**: Ki·ªÉm tra duplicate theo primary key\n",
    "3. **Value analysis**: Ph√¢n t√≠ch gi√° tr·ªã c·ªßa c√°c tr∆∞·ªùng quan tr·ªçng\n",
    "4. **Quality assessment**: ƒê√°nh gi√° t·ªïng th·ªÉ ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu\n",
    "\n",
    "### Decision Rules\n",
    "- N·∫øu c·ªôt null > 70% ‚Üí c√¢n nh·∫Øc drop\n",
    "- N·∫øu c√≥ duplicate ‚Üí x√°c ƒë·ªãnh rule x·ª≠ l√Ω (gi·ªØ b·∫£n m·ªõi nh·∫•t)\n",
    "- N·∫øu c√≥ gi√° tr·ªã b·∫•t th∆∞·ªùng ‚Üí quy·∫øt ƒë·ªãnh chu·∫©n h√≥a mapping\n",
    "\n",
    "### Tr∆∞·ªùng quan tr·ªçng c·∫ßn ki·ªÉm tra\n",
    "- gender: Ki·ªÉm tra gi√° tr·ªã h·ª£p l·ªá (male/female)\n",
    "- is_block: Boolean values\n",
    "- is_discount_by_level: Boolean values  \n",
    "- active_levera_pay: Boolean values\n",
    "- order_count, purchased_amount: Numeric values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f55e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA QUALITY ANALYSIS ===\n",
      "\n",
      "1. NULL RATIO ANALYSIS\n",
      "T·ª∑ l·ªá null theo c·ªôt (sorted):\n",
      "  email: 1.000 (100.0%)\n",
      "  total_amount_referred: 1.000 (100.0%)\n",
      "  address_postcode: 1.000 (100.0%)\n",
      "  used_reward_point: 1.000 (100.0%)\n",
      "  date_of_birth: 1.000 (100.0%)\n",
      "  currency: 0.979 (97.9%)\n",
      "  last_order_at: 0.261 (26.1%)\n",
      "  conversation_link: 0.212 (21.2%)\n",
      "  gender: 0.149 (14.9%)\n",
      "  address_commune_id: 0.101 (10.1%)\n",
      "  address_district_id: 0.101 (10.1%)\n",
      "  address_province_id: 0.101 (10.1%)\n",
      "  address_full: 0.101 (10.1%)\n",
      "  fb_id: 0.004 (0.4%)\n",
      "  phone: 0.002 (0.2%)\n",
      "  order_sources: 0.001 (0.1%)\n",
      "  name: 0.000 (0.0%)\n",
      "  customer_id: 0.000 (0.0%)\n",
      "  is_block: 0.000 (0.0%)\n",
      "  is_discount_by_level: 0.000 (0.0%)\n",
      "  inserted_at: 0.000 (0.0%)\n",
      "  purchased_amount: 0.000 (0.0%)\n",
      "  returned_order_count: 0.000 (0.0%)\n",
      "  succeed_order_count: 0.000 (0.0%)\n",
      "  order_count: 0.000 (0.0%)\n",
      "  id: 0.000 (0.0%)\n",
      "  shop_id: 0.000 (0.0%)\n",
      "  updated_at: 0.000 (0.0%)\n",
      "  referral_code: 0.000 (0.0%)\n",
      "  active_levera_pay: 0.000 (0.0%)\n",
      "  count_referrals: 0.000 (0.0%)\n",
      "  reward_point: 0.000 (0.0%)\n",
      "  current_debts: 0.000 (0.0%)\n",
      "\n",
      "2. DUPLICATE CHECK\n",
      "S·ªë l∆∞·ª£ng customer_id tr√πng l·∫∑p: 0\n",
      "S·ªë l∆∞·ª£ng id (internal) tr√πng l·∫∑p: 0\n",
      "\n",
      "3. VALUE ANALYSIS\n",
      "\n",
      "--- GENDER ANALYSIS ---\n",
      "gender\n",
      "female          19486\n",
      "male            11239\n",
      "None             5361\n",
      "Phi nh·ªã gi·ªõi        3\n",
      "Nonbinary           1\n",
      "Name: count, dtype: int64\n",
      "Invalid gender values found:\n",
      "gender\n",
      "Phi nh·ªã gi·ªõi    3\n",
      "Nonbinary       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- IS_BLOCK ANALYSIS ---\n",
      "is_block\n",
      "False    36089\n",
      "True         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- IS_DISCOUNT_BY_LEVEL ANALYSIS ---\n",
      "is_discount_by_level\n",
      "True    36090\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- ACTIVE_LEVERA_PAY ANALYSIS ---\n",
      "active_levera_pay\n",
      "False    36087\n",
      "True         3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- ORDER_COUNT ANALYSIS ---\n",
      "Count: 36090.0\n",
      "Mean: 1.12\n",
      "Min: 0.0\n",
      "Max: 11.0\n",
      "Null count: 0\n",
      "\n",
      "--- PURCHASED_AMOUNT ANALYSIS ---\n",
      "Count: 36090.0\n",
      "Mean: 222192.57\n",
      "Min: -1788000.0\n",
      "Max: 6199000.0\n",
      "Null count: 0\n",
      "\n",
      "--- REWARD_POINT ANALYSIS ---\n",
      "Count: 36090.0\n",
      "Mean: 0.00\n",
      "Min: 0.0\n",
      "Max: 0.0\n",
      "Null count: 0\n",
      "\n",
      "--- CURRENT_DEBTS ANALYSIS ---\n",
      "Count: 36090.0\n",
      "Mean: 0.00\n",
      "Min: 0.0\n",
      "Max: 0.0\n",
      "Null count: 0\n",
      "\n",
      "4. OVERALL QUALITY SUMMARY\n",
      "Total columns: 33\n",
      "Columns with >70% null: 6\n",
      "Duplicate customers: 0\n",
      "Data quality score: 81.8%\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Analysis\n",
    "print(\"=== DATA QUALITY ANALYSIS ===\")\n",
    "\n",
    "# 1. Null ratio analysis\n",
    "print(\"\\n1. NULL RATIO ANALYSIS\")\n",
    "null_ratio = customers_parsed.isnull().mean().sort_values(ascending=False)\n",
    "print(\"T·ª∑ l·ªá null theo c·ªôt (sorted):\")\n",
    "for col, ratio in null_ratio.items():\n",
    "    print(f\"  {col}: {ratio:.3f} ({ratio*100:.1f}%)\")\n",
    "\n",
    "# 2. Duplicate check\n",
    "print(f\"\\n2. DUPLICATE CHECK\")\n",
    "dup_count = customers_parsed[\"customer_id\"].duplicated().sum()\n",
    "print(f\"S·ªë l∆∞·ª£ng customer_id tr√πng l·∫∑p: {dup_count}\")\n",
    "\n",
    "# Check duplicate theo id (internal ID)\n",
    "dup_id_count = customers_parsed[\"id\"].duplicated().sum()\n",
    "print(f\"S·ªë l∆∞·ª£ng id (internal) tr√πng l·∫∑p: {dup_id_count}\")\n",
    "\n",
    "# 3. Value analysis cho c√°c tr∆∞·ªùng quan tr·ªçng\n",
    "print(f\"\\n3. VALUE ANALYSIS\")\n",
    "\n",
    "# Gender analysis\n",
    "print(\"\\n--- GENDER ANALYSIS ---\")\n",
    "if 'gender' in customers_parsed.columns:\n",
    "    gender_counts = customers_parsed['gender'].value_counts(dropna=False)\n",
    "    print(gender_counts)\n",
    "    \n",
    "    # Check for unusual values\n",
    "    valid_genders = ['male', 'female', 'Male', 'Female', 'M', 'F']\n",
    "    invalid_genders = customers_parsed[~customers_parsed['gender'].isin(valid_genders)]['gender'].value_counts()\n",
    "    if len(invalid_genders) > 0:\n",
    "        print(\"Invalid gender values found:\")\n",
    "        print(invalid_genders)\n",
    "\n",
    "# Boolean fields analysis\n",
    "boolean_fields = ['is_block', 'is_discount_by_level', 'active_levera_pay']\n",
    "for field in boolean_fields:\n",
    "    if field in customers_parsed.columns:\n",
    "        print(f\"\\n--- {field.upper()} ANALYSIS ---\")\n",
    "        value_counts = customers_parsed[field].value_counts(dropna=False)\n",
    "        print(value_counts)\n",
    "\n",
    "# Numeric fields analysis\n",
    "numeric_fields = ['order_count', 'purchased_amount', 'reward_point', 'current_debts']\n",
    "for field in numeric_fields:\n",
    "    if field in customers_parsed.columns:\n",
    "        print(f\"\\n--- {field.upper()} ANALYSIS ---\")\n",
    "        stats = customers_parsed[field].describe()\n",
    "        print(f\"Count: {stats['count']}\")\n",
    "        print(f\"Mean: {stats['mean']:.2f}\")\n",
    "        print(f\"Min: {stats['min']}\")\n",
    "        print(f\"Max: {stats['max']}\")\n",
    "        print(f\"Null count: {customers_parsed[field].isnull().sum()}\")\n",
    "\n",
    "# 4. Overall quality summary\n",
    "print(f\"\\n4. OVERALL QUALITY SUMMARY\")\n",
    "total_columns = len(customers_parsed.columns)\n",
    "high_null_columns = len(null_ratio[null_ratio > 0.7])\n",
    "print(f\"Total columns: {total_columns}\")\n",
    "print(f\"Columns with >70% null: {high_null_columns}\")\n",
    "print(f\"Duplicate customers: {dup_count}\")\n",
    "print(f\"Data quality score: {((total_columns - high_null_columns) / total_columns * 100):.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7eadae",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 6: Data Cleaning & Transformation\n",
    "\n",
    "### M·ª•c ti√™u\n",
    "- Drop c√°c c·ªôt c√≥ t·ª∑ l·ªá null cao (>70%)\n",
    "- Chu·∫©n h√≥a datetime fields\n",
    "- √âp ki·ªÉu numeric cho c√°c c·ªôt s·ªë\n",
    "- Chu·∫©n h√≥a gender field v·ªÅ M/F/O\n",
    "- X·ª≠ l√Ω c√°c gi√° tr·ªã b·∫•t th∆∞·ªùng\n",
    "\n",
    "### Quy tr√¨nh\n",
    "1. **Drop high-null columns**: T·ª± ƒë·ªông drop c·ªôt null > 70%\n",
    "2. **Datetime conversion**: Chuy·ªÉn ƒë·ªïi string sang datetime\n",
    "3. **Numeric conversion**: √âp ki·ªÉu cho c√°c c·ªôt s·ªë\n",
    "4. **String normalization**: Chu·∫©n h√≥a gender v√† c√°c tr∆∞·ªùng string\n",
    "5. **Validation**: Ki·ªÉm tra k·∫øt qu·∫£ cleaning\n",
    "\n",
    "### Decision Rules\n",
    "- Drop columns v·ªõi null > 70% (configurable threshold)\n",
    "- Convert datetime v·ªõi error handling (coerce)\n",
    "- Convert numeric v·ªõi error handling (coerce)\n",
    "- Standardize gender: male/female ‚Üí M/F, phi nh·ªã gi·ªõi ‚Üí O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550337ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA CLEANING & TRANSFORMATION ===\n",
      "\n",
      "1. DROPPING HIGH-NULL COLUMNS\n",
      "C√°c c·ªôt b·ªã drop (null > 70.0%): ['email', 'date_of_birth', 'used_reward_point', 'total_amount_referred', 'address_postcode', 'currency']\n",
      "Shape after dropping: (36090, 27)\n",
      "\n",
      "2. DATETIME CONVERSION\n",
      "Converting inserted_at to datetime...\n",
      "Converting updated_at to datetime...\n",
      "Converting last_order_at to datetime...\n",
      "\n",
      "3. NUMERIC CONVERSION\n",
      "Converting order_count to numeric...\n",
      "Converting succeed_order_count to numeric...\n",
      "Converting returned_order_count to numeric...\n",
      "Converting purchased_amount to numeric...\n",
      "Converting reward_point to numeric...\n",
      "Converting current_debts to numeric...\n",
      "Converting count_referrals to numeric...\n",
      "Converting shop_id to numeric...\n",
      "\n",
      "4. STRING NORMALIZATION\n",
      "Standardizing gender field...\n",
      "Standardizing name field...\n",
      "Standardizing phone field...\n",
      "\n",
      "5. CLEANING VALIDATION\n",
      "Final shape: (36090, 27)\n",
      "Final columns: 27\n",
      "Memory usage: 37.33 MB\n",
      "\n",
      "Data types summary:\n",
      "object            13\n",
      "int64              8\n",
      "datetime64[ns]     3\n",
      "bool               3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== SAMPLE CLEANED DATA ===\n",
      "                            customer_id                                    id  \\\n",
      "0  c7a583d6-392d-4308-a02b-67c001ee03db  e906c5c7-ea19-42e5-a971-57cf09c94417   \n",
      "1  590ba7de-e4fe-43b3-8013-27fc69937edf  6c5b40d2-ae42-4e13-8019-f3f9127d75a0   \n",
      "2  a9e62388-57c2-4834-a87c-7c1025aea92d  765c531b-743f-4f30-b6b0-0d6f3579630f   \n",
      "\n",
      "          name    shop_id gender       phone  order_count  \\\n",
      "0    Thinh Bui  230361475      M  0903693389            1   \n",
      "1  Truong Minh  230361475      M  0907809070            1   \n",
      "2  Quach Quach  230361475      M  0986533988            1   \n",
      "\n",
      "   succeed_order_count  returned_order_count  purchased_amount  ...  \\\n",
      "0                    0                     0                 0  ...   \n",
      "1                    0                     0                 0  ...   \n",
      "2                    0                     0                 0  ...   \n",
      "\n",
      "  current_debts count_referrals referral_code  \\\n",
      "0             0               0      GM5wdxsy   \n",
      "1             0               0      6zqy77Bu   \n",
      "2             0               0      uyMB3h6E   \n",
      "\n",
      "                               fb_id  order_sources  \\\n",
      "0  377626778776391_31407011708897267             -1   \n",
      "1  377626778776391_24536870619280831             -1   \n",
      "2  377626778776391_24712861355019072             -1   \n",
      "\n",
      "                                   conversation_link  address_province_id  \\\n",
      "0  https://pancake.vn/377626778776391?customer_id...                 None   \n",
      "1  https://pancake.vn/377626778776391?customer_id...                 None   \n",
      "2  https://pancake.vn/377626778776391?customer_id...                 None   \n",
      "\n",
      "   address_district_id  address_commune_id address_full  \n",
      "0                 None                None         None  \n",
      "1                 None                None         None  \n",
      "2                 None                None         None  \n",
      "\n",
      "[3 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "def drop_high_null_cols(df, threshold=0.7):\n",
    "    \"\"\"\n",
    "    X√≥a c√°c c·ªôt c√≥ t·ª∑ l·ªá null > threshold (m·∫∑c ƒë·ªãnh 70%)\n",
    "    \"\"\"\n",
    "    null_ratio = df.isnull().mean()\n",
    "    cols_to_drop = null_ratio[null_ratio > threshold].index.tolist()\n",
    "    \n",
    "    print(f\"C√°c c·ªôt b·ªã drop (null > {threshold*100}%): {cols_to_drop}\")\n",
    "    \n",
    "    return df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# B·∫Øt ƒë·∫ßu data cleaning\n",
    "print(\"=== DATA CLEANING & TRANSFORMATION ===\")\n",
    "\n",
    "# 1. Drop high-null columns\n",
    "print(\"\\n1. DROPPING HIGH-NULL COLUMNS\")\n",
    "customers_clean = drop_high_null_cols(customers_parsed, threshold=0.7)\n",
    "print(f\"Shape after dropping: {customers_clean.shape}\")\n",
    "\n",
    "# 2. Datetime conversion\n",
    "print(\"\\n2. DATETIME CONVERSION\")\n",
    "datetime_cols = [\"inserted_at\", \"updated_at\", \"last_order_at\", \"date_of_birth\"]\n",
    "for col in datetime_cols:\n",
    "    if col in customers_clean.columns:\n",
    "        print(f\"Converting {col} to datetime...\")\n",
    "        customers_clean[col] = pd.to_datetime(customers_clean[col], errors=\"coerce\")\n",
    "\n",
    "# 3. Numeric conversion\n",
    "print(\"\\n3. NUMERIC CONVERSION\")\n",
    "numeric_cols = [\n",
    "    \"order_count\", \"succeed_order_count\", \"returned_order_count\",\n",
    "    \"purchased_amount\", \"reward_point\", \"used_reward_point\",\n",
    "    \"current_debts\", \"count_referrals\", \"total_amount_referred\",\n",
    "    \"shop_id\"\n",
    "]\n",
    "for col in numeric_cols:\n",
    "    if col in customers_clean.columns:\n",
    "        print(f\"Converting {col} to numeric...\")\n",
    "        customers_clean[col] = pd.to_numeric(customers_clean[col], errors=\"coerce\")\n",
    "\n",
    "# 4. String normalization\n",
    "print(\"\\n4. STRING NORMALIZATION\")\n",
    "\n",
    "# Gender standardization\n",
    "if \"gender\" in customers_clean.columns:\n",
    "    print(\"Standardizing gender field...\")\n",
    "    customers_clean[\"gender\"] = customers_clean[\"gender\"].str.lower().replace({\n",
    "        \"male\": \"M\", \"female\": \"F\",\n",
    "        \"nam\": \"M\", \"n·ªØ\": \"F\", \n",
    "        \"phi nh·ªã gi·ªõi\": \"O\", \"nonbinary\": \"O\"\n",
    "    })\n",
    "\n",
    "# Name standardization\n",
    "if \"name\" in customers_clean.columns:\n",
    "    print(\"Standardizing name field...\")\n",
    "    customers_clean[\"name\"] = customers_clean[\"name\"].str.strip().str.title()\n",
    "\n",
    "# Phone standardization (remove non-numeric characters except comma)\n",
    "if \"phone\" in customers_clean.columns:\n",
    "    print(\"Standardizing phone field...\")\n",
    "    customers_clean[\"phone\"] = customers_clean[\"phone\"].str.replace(r'[^\\d+,]', '', regex=True)\n",
    "\n",
    "# 5. Validation\n",
    "print(\"\\n5. CLEANING VALIDATION\")\n",
    "print(f\"Final shape: {customers_clean.shape}\")\n",
    "print(f\"Final columns: {len(customers_clean.columns)}\")\n",
    "print(f\"Memory usage: {customers_clean.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Check data types\n",
    "print(f\"\\nData types summary:\")\n",
    "print(customers_clean.dtypes.value_counts())\n",
    "\n",
    "# Sample cleaned data\n",
    "print(f\"\\n=== SAMPLE CLEANED DATA ===\")\n",
    "print(customers_clean.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc641751",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 7: Load v√†o Silver Database\n",
    "\n",
    "### M·ª•c ti√™u\n",
    "- ƒê·ªãnh nghƒ©a explicit schema mapping cho t·ª´ng c·ªôt\n",
    "- Load d·ªØ li·ªáu ƒë√£ clean v√†o Silver database\n",
    "- T·∫°o b·∫£ng dim_customers v·ªõi schema t·ªëi ∆∞u\n",
    "- X√°c nh·∫≠n load th√†nh c√¥ng\n",
    "\n",
    "### Quy tr√¨nh\n",
    "1. **Schema definition**: ƒê·ªãnh nghƒ©a dtype mapping cho t·ª´ng c·ªôt\n",
    "2. **Database load**: S·ª≠ d·ª•ng to_sql v·ªõi explicit schema\n",
    "3. **Validation**: Ki·ªÉm tra s·ªë record load th√†nh c√¥ng\n",
    "4. **Schema verification**: X√°c nh·∫≠n schema trong database\n",
    "\n",
    "### Schema Strategy\n",
    "- VARCHAR(100): Cho c√°c ID fields\n",
    "- VARCHAR(255): Cho name fields\n",
    "- VARCHAR(500): Cho URL/link fields  \n",
    "- Text(): Cho c√°c field c√≥ th·ªÉ d√†i\n",
    "- BigInteger(): Cho shop_id v√† c√°c s·ªë l·ªõn\n",
    "- DateTime(): Cho timestamp fields\n",
    "- Boolean(): Cho c√°c tr∆∞·ªùng boolean\n",
    "\n",
    "> **Decision Point**: X√°c nh·∫≠n s·ªë record load th√†nh c√¥ng v√† ki·ªÉm tra schema ·ªü Silver c√≥ ƒë√∫ng v·ªõi k·ª≥ v·ªçng.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47051d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SCHEMA DEFINITION ===\n",
      "Schema mapping defined for 27 columns\n",
      "Schema mapping:\n",
      "  customer_id: VARCHAR(100)\n",
      "  id: VARCHAR(100)\n",
      "  fb_id: VARCHAR(100)\n",
      "  name: VARCHAR(255)\n",
      "  referral_code: VARCHAR(255)\n",
      "  conversation_link: VARCHAR(500)\n",
      "  phone: TEXT\n",
      "  order_sources: TEXT\n",
      "  address_full: TEXT\n",
      "  shop_id: BIGINT\n",
      "  order_count: INTEGER\n",
      "  succeed_order_count: INTEGER\n",
      "  returned_order_count: INTEGER\n",
      "  reward_point: INTEGER\n",
      "  current_debts: INTEGER\n",
      "  count_referrals: INTEGER\n",
      "  purchased_amount: FLOAT\n",
      "  inserted_at: DATETIME\n",
      "  updated_at: DATETIME\n",
      "  last_order_at: DATETIME\n",
      "  is_block: BOOLEAN\n",
      "  is_discount_by_level: BOOLEAN\n",
      "  active_levera_pay: BOOLEAN\n",
      "  gender: VARCHAR(50)\n",
      "  address_province_id: VARCHAR(50)\n",
      "  address_district_id: VARCHAR(50)\n",
      "  address_commune_id: VARCHAR(50)\n",
      "\n",
      "=== LOADING TO SILVER DATABASE ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ load 36090 records v√†o Silver: dim_customers\n",
      "‚úÖ Verification: 36090 records trong database\n",
      "‚úÖ Schema: 27 columns v·ªõi explicit typing\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.types import BigInteger, Integer, Float, DateTime, Text, VARCHAR, Boolean\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a schema mapping cho t·ª´ng c·ªôt\n",
    "print(\"=== SCHEMA DEFINITION ===\")\n",
    "\n",
    "dtype_mapping = {}\n",
    "\n",
    "# ID fields - VARCHAR(100)\n",
    "id_fields = [\"customer_id\", \"id\", \"fb_id\"]\n",
    "for field in id_fields:\n",
    "    if field in customers_clean.columns:\n",
    "        dtype_mapping[field] = VARCHAR(100)\n",
    "\n",
    "# Name fields - VARCHAR(255)  \n",
    "name_fields = [\"name\", \"referral_code\"]\n",
    "for field in name_fields:\n",
    "    if field in customers_clean.columns:\n",
    "        dtype_mapping[field] = VARCHAR(255)\n",
    "\n",
    "# URL/Link fields - VARCHAR(500)\n",
    "url_fields = [\"conversation_link\"]\n",
    "for field in url_fields:\n",
    "    if field in customers_clean.columns:\n",
    "        dtype_mapping[field] = VARCHAR(500)\n",
    "\n",
    "# Text fields - Text()\n",
    "text_fields = [\"phone\", \"email\", \"order_sources\", \"address_full\"]\n",
    "for field in text_fields:\n",
    "    if field in customers_clean.columns:\n",
    "        dtype_mapping[field] = Text()\n",
    "\n",
    "# Numeric fields\n",
    "if \"shop_id\" in customers_clean.columns:\n",
    "    dtype_mapping[\"shop_id\"] = BigInteger()\n",
    "\n",
    "# Integer fields\n",
    "integer_fields = [\"order_count\", \"succeed_order_count\", \"returned_order_count\", \n",
    "                  \"reward_point\", \"used_reward_point\", \"current_debts\", \n",
    "                  \"count_referrals\", \"total_amount_referred\"]\n",
    "for field in integer_fields:\n",
    "    if field in customers_clean.columns:\n",
    "        dtype_mapping[field] = Integer()\n",
    "\n",
    "# Float fields\n",
    "float_fields = [\"purchased_amount\"]\n",
    "for field in float_fields:\n",
    "    if field in customers_clean.columns:\n",
    "        dtype_mapping[field] = Float()\n",
    "\n",
    "# DateTime fields\n",
    "datetime_fields = [\"inserted_at\", \"updated_at\", \"last_order_at\", \"date_of_birth\"]\n",
    "for field in datetime_fields:\n",
    "    if field in customers_clean.columns:\n",
    "        dtype_mapping[field] = DateTime()\n",
    "\n",
    "# Boolean fields\n",
    "boolean_fields = [\"is_block\", \"is_discount_by_level\", \"active_levera_pay\"]\n",
    "for field in boolean_fields:\n",
    "    if field in customers_clean.columns:\n",
    "        dtype_mapping[field] = Boolean()\n",
    "\n",
    "# String fields (default)\n",
    "string_fields = [\"gender\", \"currency\", \"address_province_id\", \"address_district_id\", \n",
    "                \"address_commune_id\", \"address_postcode\"]\n",
    "for field in string_fields:\n",
    "    if field in customers_clean.columns:\n",
    "        dtype_mapping[field] = VARCHAR(50)\n",
    "\n",
    "print(f\"Schema mapping defined for {len(dtype_mapping)} columns\")\n",
    "print(\"Schema mapping:\")\n",
    "for col, dtype in dtype_mapping.items():\n",
    "    print(f\"  {col}: {dtype}\")\n",
    "\n",
    "# Load v√†o Silver database\n",
    "print(f\"\\n=== LOADING TO SILVER DATABASE ===\")\n",
    "table_name = \"dim_customers\"\n",
    "\n",
    "try:\n",
    "    customers_clean.to_sql(\n",
    "        table_name,\n",
    "        con=silver_engine,\n",
    "        if_exists=\"replace\",  # Ghi ƒë√® d·ªØ li·ªáu c≈©\n",
    "        index=False,\n",
    "        dtype=dtype_mapping\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ ƒê√£ load {customers_clean.shape[0]} records v√†o Silver: {table_name}\")\n",
    "    \n",
    "    # Verify load\n",
    "    verification_query = f\"SELECT COUNT(*) as count FROM {table_name}\"\n",
    "    verification_result = pd.read_sql(verification_query, silver_engine)\n",
    "    loaded_count = verification_result['count'].iloc[0]\n",
    "    \n",
    "    print(f\"‚úÖ Verification: {loaded_count} records trong database\")\n",
    "    print(f\"‚úÖ Schema: {len(dtype_mapping)} columns v·ªõi explicit typing\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading to Silver: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a8fe35",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 8: Data Dictionary Generation\n",
    "\n",
    "### M·ª•c ti√™u\n",
    "- T·∫°o Data Dictionary chi ti·∫øt cho b·∫£ng dim_customers\n",
    "- Document metadata c·ªßa t·ª´ng c·ªôt (data type, null %, unique count, sample values)\n",
    "- L∆∞u Data Dictionary v√†o Excel file ƒë·ªÉ tham kh·∫£o\n",
    "- T·∫°o t√†i li·ªáu tham chi·∫øu cho Gold layer design\n",
    "\n",
    "### Quy tr√¨nh\n",
    "1. **Generate dictionary**: T·∫°o DataFrame v·ªõi metadata c·ªßa t·ª´ng c·ªôt\n",
    "2. **Add business context**: Th√™m business meaning cho c√°c tr∆∞·ªùng\n",
    "3. **Export to Excel**: L∆∞u v√†o file Excel ƒë·ªÉ documentation\n",
    "4. **Summary report**: T·∫°o b√°o c√°o t·ªïng k·∫øt\n",
    "\n",
    "### Data Dictionary Fields\n",
    "- column: T√™n c·ªôt\n",
    "- dtype: Ki·ªÉu d·ªØ li·ªáu (pandas)\n",
    "- sql_type: Ki·ªÉu d·ªØ li·ªáu SQL\n",
    "- null_pct: T·ª∑ l·ªá null (%)\n",
    "- unique_count: S·ªë l∆∞·ª£ng gi√° tr·ªã unique\n",
    "- sample_values: C√°c gi√° tr·ªã m·∫´u\n",
    "- business_meaning: √ù nghƒ©a business\n",
    "- extraction_date: Ng√†y extract\n",
    "\n",
    "> **Decision Point**: D·ª±a v√†o Data Dictionary, ki·ªÉm tra l·∫°i schema Silver c√≥ ph√π h·ª£p v·ªõi Business Requirement. N·∫øu thi·∫øu c·ªôt quan tr·ªçng ho·∫∑c dtype ch∆∞a chu·∫©n, c·∫ßn quay l·∫°i b∆∞·ªõc 4-6 ƒë·ªÉ ch·ªânh s·ª≠a.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28313e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERATING DATA DICTIONARY ===\n",
      "Generated Data Dictionary for 27 columns\n",
      "\n",
      "=== DATA DICTIONARY ===\n",
      "       table_name           column_name           dtype      sql_type  \\\n",
      "0   dim_customers           customer_id          object  VARCHAR(100)   \n",
      "1   dim_customers                    id          object  VARCHAR(100)   \n",
      "2   dim_customers                  name          object  VARCHAR(255)   \n",
      "3   dim_customers               shop_id           int64        BIGINT   \n",
      "4   dim_customers                gender          object   VARCHAR(50)   \n",
      "5   dim_customers                 phone          object          TEXT   \n",
      "6   dim_customers           order_count           int64       INTEGER   \n",
      "7   dim_customers   succeed_order_count           int64       INTEGER   \n",
      "8   dim_customers  returned_order_count           int64       INTEGER   \n",
      "9   dim_customers      purchased_amount           int64         FLOAT   \n",
      "10  dim_customers         last_order_at  datetime64[ns]      DATETIME   \n",
      "11  dim_customers           inserted_at  datetime64[ns]      DATETIME   \n",
      "12  dim_customers            updated_at  datetime64[ns]      DATETIME   \n",
      "13  dim_customers              is_block            bool       BOOLEAN   \n",
      "14  dim_customers  is_discount_by_level            bool       BOOLEAN   \n",
      "15  dim_customers     active_levera_pay            bool       BOOLEAN   \n",
      "16  dim_customers          reward_point           int64       INTEGER   \n",
      "17  dim_customers         current_debts           int64       INTEGER   \n",
      "18  dim_customers       count_referrals           int64       INTEGER   \n",
      "19  dim_customers         referral_code          object  VARCHAR(255)   \n",
      "20  dim_customers                 fb_id          object  VARCHAR(100)   \n",
      "21  dim_customers         order_sources          object          TEXT   \n",
      "22  dim_customers     conversation_link          object  VARCHAR(500)   \n",
      "23  dim_customers   address_province_id          object   VARCHAR(50)   \n",
      "24  dim_customers   address_district_id          object   VARCHAR(50)   \n",
      "25  dim_customers    address_commune_id          object   VARCHAR(50)   \n",
      "26  dim_customers          address_full          object          TEXT   \n",
      "\n",
      "    null_count  null_pct  unique_count  \\\n",
      "0            0      0.00         36090   \n",
      "1            0      0.00         36090   \n",
      "2            7      0.02         25190   \n",
      "3            0      0.00             1   \n",
      "4         5361     14.85             3   \n",
      "5           90      0.25         35716   \n",
      "6            0      0.00            11   \n",
      "7            0      0.00             6   \n",
      "8            0      0.00             5   \n",
      "9            0      0.00           538   \n",
      "10        9414     26.08         26057   \n",
      "11           0      0.00         35984   \n",
      "12           0      0.00         35909   \n",
      "13           0      0.00             2   \n",
      "14           0      0.00             1   \n",
      "15           0      0.00             2   \n",
      "16           0      0.00             1   \n",
      "17           0      0.00             1   \n",
      "18           0      0.00             1   \n",
      "19           0      0.00         36090   \n",
      "20         135      0.37         35955   \n",
      "21          30      0.08             2   \n",
      "22        7648     21.19         28442   \n",
      "23        3641     10.09            63   \n",
      "24        3646     10.10           701   \n",
      "25        3649     10.11          7335   \n",
      "26        3631     10.06         32326   \n",
      "\n",
      "                                        sample_values  \\\n",
      "0   ['c7a583d6-392d-4308-a02b-67c001ee03db', '590b...   \n",
      "1   ['e906c5c7-ea19-42e5-a971-57cf09c94417', '6c5b...   \n",
      "2         ['Thinh Bui', 'Truong Minh', 'Quach Quach']   \n",
      "3                                         [230361475]   \n",
      "4                                     ['M', 'F', 'O']   \n",
      "5          ['0903693389', '0907809070', '0986533988']   \n",
      "6                                           [1, 2, 3]   \n",
      "7                                           [0, 1, 2]   \n",
      "8                                           [0, 1, 2]   \n",
      "9                                 [0, 350000, 249000]   \n",
      "10  [Timestamp('2025-04-16 05:47:31'), Timestamp('...   \n",
      "11  [Timestamp('2025-08-16 02:19:59'), Timestamp('...   \n",
      "12  [Timestamp('2025-08-16 02:19:59'), Timestamp('...   \n",
      "13                                      [False, True]   \n",
      "14                                             [True]   \n",
      "15                                      [False, True]   \n",
      "16                                                [0]   \n",
      "17                                                [0]   \n",
      "18                                                [0]   \n",
      "19               ['GM5wdxsy', '6zqy77Bu', 'uyMB3h6E']   \n",
      "20  ['377626778776391_31407011708897267', '3776267...   \n",
      "21                                   ['-1', '-1,-12']   \n",
      "22  ['https://pancake.vn/377626778776391?customer_...   \n",
      "23                              ['503', '101', '106']   \n",
      "24                        ['50303', '10123', '10603']   \n",
      "25                  ['5030312', '1012313', '1060331']   \n",
      "26  ['06 C·ª≠a ƒê·∫°i, Ph∆∞·ªùng C·ª≠a ƒê·∫°i, Th√†nh ph·ªë H·ªôi An...   \n",
      "\n",
      "                              business_meaning      extraction_date  \n",
      "0     Unique customer identifier (primary key)  2025-10-12 16:37:56  \n",
      "1              Internal system ID for customer  2025-10-12 16:37:56  \n",
      "2                           Customer full name  2025-10-12 16:37:56  \n",
      "3   Shop identifier (foreign key to dim_shops)  2025-10-12 16:37:56  \n",
      "4                      Customer gender (M/F/O)  2025-10-12 16:37:56  \n",
      "5     Customer phone numbers (comma-separated)  2025-10-12 16:37:56  \n",
      "6    Total number of orders placed by customer  2025-10-12 16:37:56  \n",
      "7                  Number of successful orders  2025-10-12 16:37:56  \n",
      "8                    Number of returned orders  2025-10-12 16:37:56  \n",
      "9               Total amount spent by customer  2025-10-12 16:37:56  \n",
      "10                   Date of last order placed  2025-10-12 16:37:56  \n",
      "11                   Record creation timestamp  2025-10-12 16:37:56  \n",
      "12                Record last update timestamp  2025-10-12 16:37:56  \n",
      "13        Customer blocked status (true/false)  2025-10-12 16:37:56  \n",
      "14      Discount by level enabled (true/false)  2025-10-12 16:37:56  \n",
      "15          Levera payment active (true/false)  2025-10-12 16:37:56  \n",
      "16               Current reward points balance  2025-10-12 16:37:56  \n",
      "17             Current outstanding debt amount  2025-10-12 16:37:56  \n",
      "18              Number of successful referrals  2025-10-12 16:37:56  \n",
      "19                      Customer referral code  2025-10-12 16:37:56  \n",
      "20             Facebook ID for social tracking  2025-10-12 16:37:56  \n",
      "21             Order sources (comma-separated)  2025-10-12 16:37:56  \n",
      "22               Link to customer conversation  2025-10-12 16:37:56  \n",
      "23                    Province ID from address  2025-10-12 16:37:56  \n",
      "24                    District ID from address  2025-10-12 16:37:56  \n",
      "25                     Commune ID from address  2025-10-12 16:37:56  \n",
      "26                           Full address text  2025-10-12 16:37:56  \n",
      "File Technical_Document/Dictionary.xlsx exists but is empty, adding header and data...\n",
      "‚úÖ Appended 27 rows to: Technical_Document/Dictionary.xlsx\n",
      "\n",
      "=== TRANSFORMATION SUMMARY ===\n",
      "Source records: 36090\n",
      "Target records: 36090\n",
      "Columns extracted: 27\n",
      "Columns dropped: 6\n",
      "Target table: Silver.dim_customers\n",
      "Data Dictionary: Technical_Document/Dictionary.xlsx\n",
      "Transformation completed: 2025-10-12 16:37:56\n"
     ]
    }
   ],
   "source": [
    "# Generate Data Dictionary\n",
    "print(\"=== GENERATING DATA DICTIONARY ===\")\n",
    "\n",
    "def get_business_meaning(column_name):\n",
    "    \"\"\"Get business meaning for each column\"\"\"\n",
    "    business_meanings = {\n",
    "        # ƒê·ªãnh danh & C∆° b·∫£n\n",
    "        \"customer_id\": \"Unique customer identifier (primary key)\",\n",
    "        \"id\": \"Internal system ID for customer\",\n",
    "        \"name\": \"Customer full name\",\n",
    "        \"shop_id\": \"Shop identifier (foreign key to dim_shops)\",\n",
    "        \n",
    "        # Th√¥ng tin c√° nh√¢n\n",
    "        \"gender\": \"Customer gender (M/F/O)\",\n",
    "        \"phone\": \"Customer phone numbers (comma-separated)\",\n",
    "        \"email\": \"Customer email addresses (comma-separated)\",\n",
    "        \"date_of_birth\": \"Customer date of birth\",\n",
    "        \n",
    "        # H√†nh vi mua h√†ng\n",
    "        \"order_count\": \"Total number of orders placed by customer\",\n",
    "        \"succeed_order_count\": \"Number of successful orders\",\n",
    "        \"returned_order_count\": \"Number of returned orders\",\n",
    "        \"purchased_amount\": \"Total amount spent by customer\",\n",
    "        \"last_order_at\": \"Date of last order placed\",\n",
    "        \n",
    "        # Th·ªùi gian\n",
    "        \"inserted_at\": \"Record creation timestamp\",\n",
    "        \"updated_at\": \"Record last update timestamp\",\n",
    "        \n",
    "        # Tr·∫°ng th√°i\n",
    "        \"is_block\": \"Customer blocked status (true/false)\",\n",
    "        \"is_discount_by_level\": \"Discount by level enabled (true/false)\",\n",
    "        \"active_levera_pay\": \"Levera payment active (true/false)\",\n",
    "        \n",
    "        # T√†i ch√≠nh & Loyalty\n",
    "        \"reward_point\": \"Current reward points balance\",\n",
    "        \"used_reward_point\": \"Total reward points used\",\n",
    "        \"current_debts\": \"Current outstanding debt amount\",\n",
    "        \"count_referrals\": \"Number of successful referrals\",\n",
    "        \"total_amount_referred\": \"Total amount from referrals\",\n",
    "        \n",
    "        # Marketing & Tracking\n",
    "        \"referral_code\": \"Customer referral code\",\n",
    "        \"fb_id\": \"Facebook ID for social tracking\",\n",
    "        \"order_sources\": \"Order sources (comma-separated)\",\n",
    "        \"conversation_link\": \"Link to customer conversation\",\n",
    "        \n",
    "        # ƒê·ªãa ch·ªâ\n",
    "        \"address_province_id\": \"Province ID from address\",\n",
    "        \"address_district_id\": \"District ID from address\",\n",
    "        \"address_commune_id\": \"Commune ID from address\",\n",
    "        \"address_full\": \"Full address text\",\n",
    "        \"address_postcode\": \"Postal code\",\n",
    "        \n",
    "        # Metadata\n",
    "        \"currency\": \"Default currency for customer\"\n",
    "    }\n",
    "    return business_meanings.get(column_name, \"No business meaning defined\")\n",
    "\n",
    "# T·∫°o Data Dictionary\n",
    "dict_data = []\n",
    "for col in customers_clean.columns:\n",
    "    col_info = {\n",
    "        \"table_name\": \"dim_customers\",\n",
    "        \"column_name\": col,\n",
    "        \"dtype\": str(customers_clean[col].dtype),\n",
    "        \"sql_type\": str(dtype_mapping.get(col, \"Not defined\")),\n",
    "        \"null_count\": customers_clean[col].isnull().sum(),\n",
    "        \"null_pct\": round(customers_clean[col].isnull().mean() * 100, 2),\n",
    "        \"unique_count\": customers_clean[col].nunique(),\n",
    "        \"sample_values\": str(customers_clean[col].dropna().unique()[:3].tolist()),\n",
    "        \"business_meaning\": get_business_meaning(col),\n",
    "        \"extraction_date\": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    dict_data.append(col_info)\n",
    "\n",
    "data_dictionary = pd.DataFrame(dict_data)\n",
    "\n",
    "# Hi·ªÉn th·ªã Data Dictionary\n",
    "print(f\"Generated Data Dictionary for {len(data_dictionary)} columns\")\n",
    "print(\"\\n=== DATA DICTIONARY ===\")\n",
    "print(data_dictionary)\n",
    "\n",
    "# Append Data Dictionary v√†o file Excel\n",
    "excel_path = \"Technical_Document/Dictionary.xlsx\"\n",
    "try:\n",
    "    from openpyxl import load_workbook\n",
    "    \n",
    "    # Ki·ªÉm tra file Excel c√≥ t·ªìn t·∫°i kh√¥ng\n",
    "    try:\n",
    "        # Load workbook hi·ªán t·∫°i\n",
    "        wb = load_workbook(excel_path)\n",
    "        \n",
    "        # L·∫•y sheet ƒë·∫ßu ti√™n\n",
    "        ws = wb.active\n",
    "        \n",
    "        # Ki·ªÉm tra xem c√≥ d·ªØ li·ªáu c≈© kh√¥ng\n",
    "        if ws.max_row > 1:\n",
    "            print(f\"Found existing data in {excel_path}, appending new data...\")\n",
    "        else:\n",
    "            print(f\"File {excel_path} exists but is empty, adding header and data...\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {excel_path} not found, creating new file...\")\n",
    "        wb = None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {excel_path}: {str(e)}, creating new file...\")\n",
    "        wb = None\n",
    "    \n",
    "    if wb is None:\n",
    "        # T·∫°o file m·ªõi v·ªõi header\n",
    "        data_dictionary.to_excel(excel_path, index=False, sheet_name='Data_Dictionary')\n",
    "        print(f\"‚úÖ Created new file: {excel_path}\")\n",
    "    else:\n",
    "        # Append v√†o file hi·ªán t·∫°i\n",
    "        from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "        \n",
    "        # T√¨m d√≤ng cu·ªëi c√πng c√≥ d·ªØ li·ªáu\n",
    "        last_row = ws.max_row\n",
    "        \n",
    "        # Th√™m d·ªØ li·ªáu m·ªõi t·ª´ d√≤ng ti·∫øp theo\n",
    "        for r in dataframe_to_rows(data_dictionary, index=False, header=False):\n",
    "            last_row += 1\n",
    "            for c_idx, value in enumerate(r, 1):\n",
    "                ws.cell(row=last_row, column=c_idx, value=value)\n",
    "        \n",
    "        # L∆∞u file\n",
    "        wb.save(excel_path)\n",
    "        print(f\"‚úÖ Appended {len(data_dictionary)} rows to: {excel_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error appending to Data Dictionary: {str(e)}\")\n",
    "    # Fallback: t·∫°o file m·ªõi\n",
    "    try:\n",
    "        data_dictionary.to_excel(excel_path, index=False)\n",
    "        print(f\"‚úÖ Created new file as fallback: {excel_path}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå Error creating fallback file: {str(e2)}\")\n",
    "\n",
    "# Summary Report\n",
    "print(f\"\\n=== TRANSFORMATION SUMMARY ===\")\n",
    "print(f\"Source records: {len(customers_df)}\")\n",
    "print(f\"Target records: {len(customers_clean)}\")\n",
    "print(f\"Columns extracted: {len(customers_clean.columns)}\")\n",
    "print(f\"Columns dropped: {len(customers_parsed.columns) - len(customers_clean.columns)}\")\n",
    "print(f\"Target table: Silver.dim_customers\")\n",
    "print(f\"Data Dictionary: {excel_path}\")\n",
    "print(f\"Transformation completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
